# =======================================================
# WhisperEngine Local AI Configuration
# Privacy-focused configuration using local AI models and on-premise infrastructure
# =======================================================

# üè† LOCAL AI SETUP:
#   1. Install LM Studio or Ollama
#   2. Download a model (Llama 3.2 3B or 8B recommended)
#   3. Start local server
#   4. Copy this config to .env

# =======================================================
# DISCORD CONFIGURATION
# =======================================================
DISCORD_BOT_TOKEN=your_discord_bot_token_here
DISCORD_BOT_NAME=WhisperEngine-Local
ADMIN_USER_IDS=your_discord_user_id_here

# =======================================================
# CHARACTER CONFIGURATION (CDL)
# =======================================================
CDL_DEFAULT_CHARACTER=characters/default_assistant.json

# Local character options:
# CDL_DEFAULT_CHARACTER=characters/dream_of_the_endless.json
# CDL_DEFAULT_CHARACTER=characters/examples/elena-rodriguez.json
# CDL_DEFAULT_CHARACTER=characters/examples/marcus-chen.json

# =======================================================
# LOCAL LLM CONFIGURATION
# =======================================================
# LM Studio (recommended for beginners)
LLM_CHAT_API_URL=http://localhost:1234/v1
LLM_CHAT_API_KEY=not-needed
LLM_CHAT_MODEL=local-model

# Alternative: Ollama
# LLM_CHAT_API_URL=http://localhost:11434/v1
# LLM_CHAT_API_KEY=not-needed
# LLM_CHAT_MODEL=llama3.2:3b

# Alternative: Text Generation WebUI
# LLM_CHAT_API_URL=http://localhost:5000/v1
# LLM_CHAT_API_KEY=not-needed
# LLM_CHAT_MODEL=local

# =======================================================
# LOCAL MEMORY SYSTEM (VECTOR-NATIVE)
# =======================================================
MEMORY_SYSTEM_TYPE=vector
VECTOR_QDRANT_HOST=localhost
VECTOR_QDRANT_PORT=6333
VECTOR_QDRANT_COLLECTION=whisperengine_local
VECTOR_EMBEDDING_MODEL=snowflake/snowflake-arctic-embed-xs

# Alternative local embedding models:
# VECTOR_EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
# VECTOR_EMBEDDING_MODEL=BAAI/bge-small-en-v1.5

# =======================================================
# LOCAL DATABASE CONFIGURATION
# =======================================================
# PostgreSQL (local instance)
POSTGRESQL_HOST=localhost
POSTGRESQL_PORT=5432
POSTGRESQL_DATABASE=whisper_engine_local
POSTGRESQL_USERNAME=local_user
POSTGRESQL_PASSWORD=localpassword123

# Redis (local instance)
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=
REDIS_DB=0

# =======================================================
# VOICE SYSTEM (OPTIONAL - REQUIRES API)
# =======================================================
# Disable voice for fully local setup
VOICE_SERVICE_TYPE=disabled

# Enable voice with ElevenLabs (breaks full local privacy)
# VOICE_SERVICE_TYPE=discord_elevenlabs
# ELEVENLABS_API_KEY=your_elevenlabs_api_key_here
# ELEVENLABS_VOICE_ID=21m00Tcm4TlvDq8ikWAM

# =======================================================
# ENGAGEMENT ENGINE
# =======================================================
ENGAGEMENT_ENGINE_TYPE=basic
ENGAGEMENT_ENABLED=true
ENGAGEMENT_CHECK_INTERVAL=600
ENGAGEMENT_MEMORY_THRESHOLD=5

# =======================================================
# LOCAL PRIVACY SETTINGS
# =======================================================
# Maximum privacy mode
PRIVACY_MODE=maximum
DATA_RETENTION_DAYS=30

# No external analytics
METRICS_COLLECTION_ENABLED=false
EXTERNAL_LOGGING_ENABLED=false

# =======================================================
# PERFORMANCE (LOCAL OPTIMIZED)
# =======================================================
# Conservative settings for local hardware
LOG_LEVEL=INFO
CONSOLE_LOG_LEVEL=INFO
DEBUG_MODE=false

# Local performance optimization
MEMORY_DEBUG_ENABLED=false
CONVERSATION_CONTEXT_LIMIT=5
CONVERSATION_MEMORY_LIMIT=25

# =======================================================
# LOCAL FEATURES
# =======================================================
# Enable useful local features
HEALTH_CHECK_ENABLED=true
HEALTH_CHECK_PORT=9090

# Disable cloud features
EXPERIMENTAL_FEATURES_ENABLED=false
PHASE4_INTEGRATION_ENABLED=false

# =======================================================
# DOCKER INFRASTRUCTURE (LOCAL)
# =======================================================
# For Docker Compose local setup
QDRANT_HTTP_PORT=6333
POSTGRES_PORT=5432
REDIS_PORT=6379

# =======================================================
# üè† LOCAL AI READY!
# 
# Privacy benefits:
# ‚úÖ All AI processing happens locally
# ‚úÖ No data sent to external AI APIs
# ‚úÖ Full control over your data
# ‚úÖ No monthly API costs
# 
# Setup steps:
# 1. Install LM Studio: https://lmstudio.ai
# 2. Download a model (Llama 3.2 3B)
# 3. Start local server (port 1234)
# 4. Run: ./bot.sh start dev
# =======================================================